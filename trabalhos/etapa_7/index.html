<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Etapa 7 | Relatório Final do Trabalho (RFT) - Grupo 8 - ICPG</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
  <style>
    :root { --primary: #2563eb; --secondary: #111827; --accent: #e11d48; --bg: #f5f6fa; --white: #fff; --gray: #6b7280; --border: #e5e7eb; --radius: 8px; --shadow: 0 2px 8px rgba(0, 0, 0, 0.04); --transition: 0.2s; }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    html, body { background: var(--bg); color: var(--secondary); font-family: 'Roboto', sans-serif; font-size: 17px; line-height: 1.6; min-height: 100vh; }
    body { display: flex; flex-direction: column; min-height: 100vh; }
    main.container { max-width: 900px; margin: 0 auto; background: var(--white); border-radius: var(--radius); box-shadow: var(--shadow); padding: 36px 24px 24px 24px; margin-bottom: 32px; margin-top: 24px; }
    section { margin-bottom: 36px; }
    h2 { font-size: 1.4rem; font-weight: 600; color: var(--primary); margin-bottom: 18px; letter-spacing: 0.2px; }
    h3 { font-size: 1.1rem; font-weight: 500; color: var(--secondary); margin-bottom: 12px; }
    h4 { font-size: 1rem; font-weight: 500; color: var(--primary); margin-bottom: 8px; }
    ul, ol { margin-left: 18px; margin-bottom: 12px; }
    li { margin-bottom: 6px; }
    .section { background: #f3f4f6; padding: 18px 14px; border-radius: var(--radius); margin-bottom: 18px; }
    table { width: 100%; border-collapse: collapse; margin-bottom: 18px; }
    th, td { padding: 8px 10px; border: 1px solid var(--border); text-align: left; }
    th { background: var(--primary); color: var(--white); }
    tr:nth-child(even) { background: #f9fafb; }
    tr:nth-child(odd) { background: #f3f4f6; }
    code, pre { background: #f9fafb; border-radius: 6px; padding: 2px 6px; font-size: 0.98em; }
    .muted { color: var(--gray); }
    .video-container { text-align: center; margin: 24px 0; }
    video { max-width: 100%; border-radius: 10px; box-shadow: var(--shadow); }
    footer.rodape {
        text-align: center;
        padding: 24px 0 18px 0;
        color: var(--gray);
        font-size: 0.98em;
        border-top: 1px solid var(--border);
        background: #fff;
        margin-top: auto;
    }
    @media (max-width: 700px) { main.container { padding-left: 8px; padding-right: 8px; } h2 { font-size: 1.1rem; } h3 { font-size: 1rem; } .section { padding: 12px 7px; } }
        .image-gallery {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: center;
            margin-top: 20px;
        }

        .image-gallery figure {
            margin: 0;
            text-align: center;
            width: calc(33% - 10px);
        }

        .image-gallery img {
            max-width: 100%;
            border-radius: var(--radius);
            box-shadow: var(--shadow);
        }

        .image-gallery figcaption {
            margin-top: 8px;
            font-size: 0.9em;
            color: var(--gray);
        }
  </style>
</head>
<body>
<main class="container">
  <section>
    <h2>Relatório Final do Trabalho (RFT) — Etapa 7</h2>
    <p class="muted">Grupo 8 - ICPG | Visão Computacional - UFABC</p>
  </section>

    <section class="section">
    <h3>Introdução</h3>
    <ul>
      <li><b>Objetivo:</b> Desenvolver um sistema de visão computacional para leitura automática de placas de veículos, aplicando conceitos fundamentais da disciplina.</li>
      <li><b>Cenário de Aplicação (CA):</b> Automatização do registro de placas em estacionamentos e canteiros de obras, reduzindo erros humanos e otimizando processos.</li>    
    </ul>
  </section>

  <section class="section">
    <h3>Fundamentação Teórica</h3>
    <p>O projeto se baseia em conceitos fundamentais da visão computacional para processar e interpretar as imagens capturadas.</p>
    
    <h4>Calibragem de Câmera</h4>
    <p>A calibração de câmera é um passo crucial para corrigir as distorções geométricas introduzidas pela lente. O nosso sistema inclui um módulo de calibração que, a partir de imagens de um padrão de xadrez, calcula a matriz intrínseca da câmera (distância focal, centro óptico) e os coeficientes de distorção. Com esses parâmetros, o SPV pode "desentortar" as imagens antes do processamento, garantindo que as linhas retas no mundo real apareçam retas na imagem, o que melhora significativamente a precisão na detecção dos contornos da placa.</p>

    <h4>Filtragem e Detecção de Bordas</h4>
    <p>O pré-processamento das imagens é essencial para destacar as características de interesse. Utilizamos a conversão para escala de cinza para simplificar a informação de cor e o Filtro Gaussiano para suavizar a imagem e remover ruídos de alta frequência. Em seguida, o algoritmo de Canny é aplicado para detectar as bordas (edges), que são as transições abruptas de intensidade. Este passo é fundamental para a detecção de contornos, pois as bordas da placa se tornam proeminentes.</p>

    <h4>Detecção de Contornos e Formas Geométricas</h4>
    <p>Após a detecção de bordas, o sistema busca por contornos fechados na imagem. Cada contorno é aproximado por uma forma poligonal. Filtramos esses contornos para encontrar aqueles que são retangulares e que possuem uma proporção (largura/altura) compatível com a de uma placa veicular (aproximadamente 4:1). Esta abordagem geométrica é uma das principais estratégias do nosso SPV para localizar as Regiões de Interesse (ROIs).</p>

    <h4>Reconhecimento Óptico de Caracteres (OCR)</h4>
    <p>Uma vez que uma ROI é isolada, ela é enviada para um motor de OCR. Nosso sistema suporta dois dos mais populares motores de código aberto:</p>
    <ul>
      <li><b>Tesseract:</b> Desenvolvido pela HP e mantido pelo Google, é um motor de OCR robusto que analisa o layout do texto e reconhece caracteres individualmente usando redes neurais (LSTM). Ele é altamente configurável, permitindo ajustar modos de segmentação de página (PSMs) para otimizar a leitura em diferentes contextos.</li>
      <li><b>EasyOCR:</b> Uma biblioteca mais recente e de fácil uso, baseada em PyTorch. Ela utiliza um modelo CRNN (Rede Neural Convolucional-Recorrente) que processa a imagem como um todo, sendo eficaz na leitura de sequências de texto, como as encontradas em placas.</li>
    </ul>
    <p>O SPV pode utilizar um ou ambos os motores em paralelo, aproveitando a força de cada um e melhorando a acurácia geral do reconhecimento.</p>
  </section>

  <section class="section">
    <h3>Materiais e Métodos</h3>
    <ul>
      <li><b>Modelagem Funcional do SPV (MF):</b> <a href="../etapa_2/index.html">Ver Etapa 2</a></li>
      <li><b>Descrição da implementação:</b> O sistema foi implementado em Python, utilizando OpenCV, pytesseract e easyocr. O código principal está em <code>plates_recognizer.py</code>.</li>
      <li><b>Lista dos arquivos:</b>
        <ul>
          <li><code>plates_recognizer.py</code> (código principal)</li>
          <li><code>haarcascade_russian_plate_number.xml</code> (classificador Haar Cascade, fallback para detecção de placas)</li>
          <li><code>requirements.txt</code> (dependências)</li>
          <li><code>gerador_placa.html</code> (gerador de placas de teste)</li>
          <li>Imagens, vídeos e arquivos auxiliares na pasta <code>projeto/</code></li>
        </ul>
      </li>
      <li><b>Análise técnica:</b> O sistema atendeu ao contexto proposto, realizando detecção e leitura de placas em tempo real, com métricas qualitativas (acerto visual, facilidade de uso) e quantitativas (tempo de resposta, taxa de acerto em amostras).</li>
    </ul>

    <h4>Detalhamento da Implementação do SPV</h4>
    <p>O coração do nosso projeto é o script <code>plates_recognizer.py</code>, que implementa o pipeline de reconhecimento de forma modular e assíncrona.</p>
    <ul>
      <li><b>Captura e Calibração:</b> O sistema inicia a captura de vídeo da webcam e, se um arquivo de calibração for fornecido, aplica a correção de distorção a cada quadro.</li>
      <li><b>Detecção Híbrida de ROIs:</b> Para encontrar as placas, usamos uma combinação de Haar Cascade (um método rápido baseado em aprendizado de máquina para detecção de objetos) e a detecção de contornos descrita anteriormente. Os resultados de ambos são unidos e filtrados para remover duplicatas.</li>
      <li><b>OCR Assíncrono:</b> Para não travar a interface de vídeo, as ROIs candidatas são enviadas para um pool de processos de OCR que rodam em paralelo. Isso garante uma experiência de usuário fluida, mesmo enquanto o processamento mais pesado acontece em segundo plano.</li>
      <li><b>Pré-processamento para OCR:</b> Antes de enviar ao motor de OCR, cada ROI passa por um pré-processamento específico para melhorar a legibilidade, como a aplicação de limiarização adaptativa, que binariza a imagem de forma inteligente, separando o texto do fundo.</li>
    </ul>

    <h4>Exemplo de Pré-processamento de Imagem</h4>
    <div class="image-gallery">
      <figure>
        <img src="../projeto/plate_processing_sample/step0_original_frame.png" alt="Quadro Original">
        <figcaption>1. Quadro Original</figcaption>
      </figure>
      <figure>
        <img src="../projeto/plate_processing_sample/step1_gray_image (1).png" alt="Imagem em Escala de Cinza">
        <figcaption>2. Escala de Cinza</figcaption>
      </figure>
      <figure>
        <img src="../projeto/plate_processing_sample/step3_edges_canny_80_180.png" alt="Detecção de Bordas (Canny)">
        <figcaption>3. Bordas (Canny)</figcaption>
      </figure>
    </div>
  </section>

  <section class="section">
    <h3>Laboratório Experimental</h3>
    <ul>
      <li><b>Roteiro do Laboratório Experimental:</b> <a href="../etapa_5/index.html">Ver Etapa 5</a></li>
      <li><b>Análise dos Resultados do Teste de Campo (TCS):</b> <a href="../etapa_6/index.html">Ver Etapa 6</a></li>
      <li>Os experimentos foram realizados com diferentes usuários, em condições reais de iluminação e posicionamento, e os resultados foram registrados e avaliados conforme o roteiro.</li>
      <li>As médias das avaliações e opiniões subjetivas dos usuários estão documentadas nos formulários e planilhas anexas.</li>
    </ul>

    <div class="forms">
      <h4>Respostas do questionário do Google Forms</h4>
      <div style="display: flex; justify-content: center; gap: 18px; flex-direction: column;">
        <img src="./q1.png" alt="Gráfico da pergunta 1" >
        <img src="./q2.png" alt="Gráfico da pergunta 2" >
        <img src="./q3.png" alt="Gráfico da pergunta 3" >
        <img src="./q4.png" alt="Gráfico da pergunta 4" >
        <img src="./q5.png" alt="Gráfico da pergunta 5" >
      </div>
    </div>
    </div>
  </section>

  <section class="section">
    <h3>Conclusões</h3>
    <ul>
      <li>Os objetivos propostos foram atingidos, com o sistema funcionando de acordo com a modelagem e o contexto definidos.</li>
      <li>Pontos positivos: automação eficiente, interface amigável, fácil adaptação a diferentes ambientes.</li>
      <li>Pontos a melhorar: sensibilidade a condições extremas de iluminação e ângulos muito inclinados.</li>
      <li>O projeto proporcionou aprendizado prático dos conceitos de visão computacional.</li>
    </ul>
  </section>

  <section class="section">
    <h3>Referências Bibliográficas</h3>
    <ul>
      <li>GONZALEZ, R. C.; WOODS, R. E. Processamento Digital de Imagens. 4ª ed. Pearson, 2018.</li>
      <li>OpenCV Documentation. <a href="https://docs.opencv.org/">https://docs.opencv.org/</a></li>
      <li>Pytesseract Documentation. <a href="https://pypi.org/project/pytesseract/">https://pypi.org/project/pytesseract/</a></li>
      <li>EasyOCR Documentation. <a href="https://www.jaided.ai/easyocr/">https://www.jaided.ai/easyocr/</a></li>
    </ul>
  </section>

  <section class="section">
    <h3>Anexos</h3>
    <ul>
      <li>Todos os códigos-fonte, imagens, vídeos e arquivos auxiliares estão disponíveis na pasta <code>projeto/</code> deste repositório.</li>
    </ul>
  </section>

  <section class="section">
    <h3>Apresentação em Vídeo</h3>
    <div class="video-container">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/GRdp6Undwl0?si=7h9SpGzXZkIytzg9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      <p class="muted">Demonstração do sistema SPV em funcionamento durante o Teste de Campo.</p>
    </div>
  </section>
</main>
<footer class="rodape">
  &copy; 2025 Grupo 8 - ICPG | Visão Computacional - UFABC<br>
  <img src="https://upload.wikimedia.org/wikipedia/commons/e/ee/Ufabc_logo.png" alt="UFABC Logo" height="32" style="margin-top:10px; display: block; margin-left: auto; margin-right: auto;">
</footer>
</body>
</html>
