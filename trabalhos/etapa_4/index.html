<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Etapa 4 | Desenvolvimento do Sistema de Processamento Visual (SPV) - Grupo 8 - ICPG</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        :root { --primary: #2563eb; --secondary: #111827; --accent: #e11d48; --bg: #f5f6fa; --white: #fff; --gray: #6b7280; --border: #e5e7eb; --radius: 8px; --shadow: 0 2px 8px rgba(0, 0, 0, 0.04); --transition: 0.2s; }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        html, body { background: var(--bg); color: var(--secondary); font-family: 'Roboto', sans-serif; font-size: 17px; line-height: 1.6; min-height: 100vh; }
        body { display: flex; flex-direction: column; min-height: 100vh; }
        main.container { max-width: 900px; margin: 0 auto; background: var(--white); border-radius: var(--radius); box-shadow: var(--shadow); padding: 36px 24px 24px 24px; margin-bottom: 32px; margin-top: 24px; }
        section { margin-bottom: 36px; }
        h2 { font-size: 1.4rem; font-weight: 600; color: var(--primary); margin-bottom: 18px; letter-spacing: 0.2px; }
        h3 { font-size: 1.1rem; font-weight: 500; color: var(--secondary); margin-bottom: 12px; }
        h4 { font-size: 1rem; font-weight: 500; color: var(--primary); margin-bottom: 8px; }
        ul { margin-left: 18px; margin-bottom: 12px; }
        li { margin-bottom: 6px; }
        .section { background: #f3f4f6; padding: 18px 14px; border-radius: var(--radius); margin-bottom: 18px; }
        code, pre { background: #f9fafb; border-radius: 6px; padding: 2px 6px; font-size: 0.98em; }
        table { width: 100%; border-collapse: collapse; margin-bottom: 18px; }
        th, td { padding: 8px 10px; border: 1px solid var(--border); text-align: left; }
        th { background: var(--primary); color: var(--white); }
        tr:nth-child(even) { background: #f9fafb; }
        tr:nth-child(odd) { background: #f3f4f6; }
        footer.rodape { text-align: center; padding: 24px 0 18px 0; color: var(--gray); font-size: 0.98em; border-top: 1px solid var(--border); background: var(--white); margin-top: auto; }
        @media (max-width: 700px) { main.container { padding-left: 8px; padding-right: 8px; } main.container { padding: 18px 6px 12px 6px; } h2 { font-size: 1.1rem; } h3 { font-size: 1rem; } .section { padding: 12px 7px; } }
    </style>
</head>
<body>
<main class="container">
    <section id="etapa4">
        <h2>Etapa 4: Desenvolvimento do Sistema de Processamento Visual (SPV)</h2>
        <div class="section">
            <h3>Visão Geral</h3>
            <p>
                O Sistema de Processamento Visual (SPV) desenvolvido pelo Grupo 8 tem como objetivo automatizar a leitura de placas de veículos em tempo real, utilizando técnicas de visão computacional. O sistema foi implementado em Python, utilizando a API OpenCV, e é capaz de capturar imagens de uma webcam, detectar placas de veículos e realizar OCR para extrair o texto das placas, registrando os resultados de forma prática e acessível.
            </p>
        </div>
        <div class="section">
            <h3>Requisitos Atendidos</h3>
            <ul>
                <li>Utilização da API <b>OpenCV</b> para processamento de imagens e vídeo.</li>
                <li>Execução no sistema operacional Ubuntu-Linux, compatível com o laboratório didático.</li>
                <li>Uso de webcam para captura em tempo real.</li>
                <li>Implementação própria dos alunos, sem uso de trabalhos de terceiros.</li>
                <li>Utilização de bibliotecas públicas e notórias (<code>OpenCV</code>, <code>pytesseract</code>, <code>easyocr</code>).</li>
                <li>Cálculos e processamento "on-the-fly" para visualização e extração de resultados.</li>
                <li>Cabeçalho de autoria e exemplo de chamada presentes nos arquivos de código.</li>
                <li>Título do programa e nome da equipe exibidos nas janelas do sistema.</li>
                <li>Atendimento ao contexto e cenário definidos nas etapas anteriores.</li>
                <li>Facilidade de uso para usuários leigos, com interface simples e resultados claros.</li>
            </ul>
        </div>
        <div class="section">
            <h3>Descrição da Implementação</h3>
            <ul>
                <li><b>Captura de vídeo:</b> O sistema utiliza a webcam do computador para capturar frames em tempo real.</li>
                <li><b>Pré-processamento:</b> As imagens capturadas passam por redimensionamento, conversão para escala de cinza, redução de ruído e operações morfológicas.</li>
                <li><b>Detecção de placas:</b> Utiliza-se Haar Cascade e análise de contornos para localizar regiões candidatas a placas nos frames.</li>
                <li><b>Reconhecimento de caracteres (OCR):</b> O sistema oferece suporte a dois motores de OCR (<code>pytesseract</code> e <code>easyocr</code>), podendo operar em modo paralelo para maior desempenho.</li>
                <li><b>Calibração de câmera:</b> Função dedicada para calibrar a câmera e corrigir distorções ópticas, conforme teoria da disciplina.</li>
                <li><b>Registro e exibição:</b> As placas reconhecidas são exibidas na tela e podem ser salvas para consulta posterior.</li>
                <li><b>Interface:</b> O usuário pode operar o sistema por meio de atalhos simples (ex: <code>q</code> para sair, <code>d</code> para debug, <code>p</code> para pausar).</li>
            </ul>
        </div>
        <div class="section">
            <h3>Exemplo de Execução</h3>
            <p>Para executar o sistema no laboratório Ubuntu-Linux, utilize o seguinte comando no terminal:</p>
            <pre><code>python3 plates_recognizer.py --camera</code></pre>
            <p>Outros parâmetros opcionais estão documentados no cabeçalho do código.</p>
        </div>
        <div class="section">
            <h3>Estrutura dos Arquivos</h3>
            <ul>
                <li><b>plates_recognizer.py</b>: Código principal do sistema SPV.</li>
                <li><b>haarcascade_russian_plate_number.xml</b>: Classificador Haar Cascade para detecção de placas.</li>
                <li><b>requirements.txt</b>: Lista de dependências do projeto.</li>
                <li><b>gerador_placa.html</b>: Utilitário para gerar placas de teste.</li>
            </ul>
        </div>
        <div class="section">
            <h3>Imagens do Sistema</h3>
            <p>Exemplo de interface do sistema em execução:</p>
            <img src="../etapa_2/block-diagram-license-plate.png" alt="Diagrama de Blocos do Sistema" style="max-width:100%;margin-bottom:12px;">
        </div>
        <div class="section">
            <h3>Exemplos de Código do Sistema</h3>
            <p>Abaixo, alguns trechos ilustrativos do código <b>plates_recognizer.py</b> que demonstram as principais funcionalidades do sistema:</p>
            <h4>1. Inicialização e Execução da Câmera</h4>
            <pre><code>if __name__ == "__main__":
    main()

def main():
    # ... argumentos omitidos ...
    if args.camera:
        recognizer.run_camera(cam_index=args.cam_index, debug=args.debug)
</code></pre>
            <p><i>Este trecho mostra como o sistema é iniciado e como a função principal executa a captura da webcam.</i></p>
            <h4>2. Detecção de Placas no Frame</h4>
            <pre><code>def detect_plate_in_frame(self, frame, debug=False):
    proc, scale = self._resize_for_speed(frame)
    regions = self.remove_duplicate_regions(
        self.detect_plate_regions_haar(proc) + self.detect_plate_regions_contour(proc)
    )
    # ... OCR e validação ...
    return plates, boxes
</code></pre>
            <p><i>Função responsável por detectar regiões candidatas a placas no frame, utilizando Haar Cascade e contornos.</i></p>
            <h4>3. Reconhecimento de Caracteres (OCR)</h4>
            <pre><code>def _tesseract_worker(payload):
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    # ... pré-processamento ...
    data = pytesseract.image_to_data(v, config=cfg, output_type=pytesseract.Output.DICT)
    # ... filtra resultados ...
    return outs
</code></pre>
            <p><i>Trecho do worker de OCR usando Tesseract, responsável por extrair o texto das regiões detectadas.</i></p>
            <h4>4. Calibração de Câmera</h4>
            <pre><code>def calibrate_camera(self, cam_index, output_file, checkerboard, num_images=15):
    # ... captura imagens do tabuleiro ...
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)
    np.savez(output_file, mtx=mtx, dist=dist)
</code></pre>
            <p><i>Função que realiza a calibração da câmera, salvando os parâmetros para correção de distorção.</i></p>
        </div>
        <div class="section">
            <h3>Observações Finais</h3>
            <ul>
                <li>O sistema foi desenvolvido integralmente pelos membros do Grupo 8, seguindo as diretrizes da disciplina.</li>
                <li>Todos os conceitos obrigatórios de visão computacional foram aplicados: filtragem, transformações geométricas, calibração de câmera, propriedades intrínsecas/extrínsecas, e OCR.</li>
                <li>O sistema está pronto para ser utilizado por usuários leigos, com documentação e interface acessível.</li>
            </ul>
        </div>
    </section>
</main>
<footer class="rodape" style="text-align: center;">
    &copy; 2025 Grupo 8 - ICPG | Visão Computacional - UFABC<br>
    <img src="https://upload.wikimedia.org/wikipedia/commons/e/ee/Ufabc_logo.png" alt="UFABC Logo" height="32" style="margin-top:10px; display: block; margin-left: auto; margin-right: auto;">
</footer>
</body>
</html>